# -*- coding: utf-8 -*-
"""KaggleTitanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TJiwN28I_Zcily4GAQFG1Rk8GgZcrFtJ

### This is a project for the Kaggle competition with the Titanic Dataset 
The task is straightforward: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.
"""

# Commented out IPython magic to ensure Python compatibility.
# analitics
import pandas as pd
import numpy as np
import random as rnd

# visualization
import seaborn as sns
import matplotlib.pyplot as plt
import time
# %matplotlib inline

# machine learning
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score
from sklearn.pipeline import Pipeline

import warnings
warnings.filterwarnings('ignore')

"""###Loading data"""

train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')
combined = [train_df, test_df]

train_df.head()

test_df.head()

"""###Preprocessing data

Let's take a look at the missing values:
"""

print(train_df.isnull().sum())
print('\n')
print(test_df.isnull().sum())

"""It makes sense to delete the Cabin feature due to its lack of values. We may choose to drop the Ticket column as well, since it may not have a significant impact on the survival outcome. We may also fill in the missing values for columns such as Age and Fare with relevant statistics such as the median or mean of the column."""

train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)
test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)
combined = [train_df, test_df]

for dataset in combined:
    mean = train_df["Age"].mean()
    std = test_df["Age"].std()
    nulls = dataset["Age"].isnull().sum()
    # compute random numbers between the mean, std and is_null
    rand_age = np.random.randint(mean - std, mean + std, size = nulls)
    # fill NaN values in Age column with random values generated
    age_slice = dataset["Age"].copy()
    age_slice[np.isnan(age_slice)] = rand_age
    dataset["Age"] = age_slice
    dataset["Age"] = train_df["Age"].astype(int)

print(train_df.isnull().sum())
print('\n')
print(test_df.isnull().sum())

"""For the embarked feature we'll take the most common one and for the Fare feature we'll take the mean."""

common_value = train_df.Embarked.value_counts().index[0]
train_df["Embarked"] = train_df["Embarked"].fillna(common_value)

test_df = test_df.fillna(test_df['Fare'].mean())

combined = [train_df, test_df]

train_df.head()

"""We can also extract the title in the names and create a new feature instead of Name."""

for dataset in combined:
    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\.', expand=False)

pd.crosstab(train_df['Title'], train_df['Sex'])
pd.crosstab(test_df['Title'], test_df['Sex'])

"""We'll reduce the number of titles and combine the rarest ones:"""

for dataset in combined:
    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\
 	'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')

    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')
    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')
    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')

train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()

"""Now we'll encode the titles with numbers:"""

title_mapping = {"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5}
for dataset in combined:
    dataset['Title'] = dataset['Title'].map(title_mapping)
    dataset['Title'] = dataset['Title'].fillna(0)

print(train_df.shape)
print(test_df.shape)

train_df, test_df = combined
train_df = train_df.drop(['Name'], axis=1)
test_df = test_df.drop(['Name'], axis=1)
combined = [train_df, test_df]
train_df.head()

test_df.head()

"""Finally, let's convert 'Sex' and 'Embarked' to numerical features using LabelEncoder."""

le = LabelEncoder()

for dataset in combined:
  dataset["Sex"]= le.fit_transform(dataset["Sex"])
  dataset["Embarked"]= le.fit_transform(dataset["Embarked"])

"""For convenience, let's also place the target column as the last one"""

columns = train_df.columns.tolist()
columns.insert(len(columns), columns.pop(columns.index('Survived')))
train_df = train_df.loc[:, columns]
train_df.head()

test_df.head()

"""Now we are ready to apply models for further analysis.

###Applying models
First, we extract the train and the test set. We'll also add the validation set to check how well our models perform on new data (since we don't know the target column for the test set - for this competition).
"""

X_train, X_val, Y_train, Y_val = train_test_split(train_df.drop(["Survived", "PassengerId"], axis=1), 
                                                  train_df["Survived"], 
                                                  train_size=0.9, 
                                                  random_state=123)

#X_train = train_df.drop(["Survived", "PassengerId"], axis=1)
#Y_train = train_df["Survived"]
X_test  = test_df.drop("PassengerId", axis=1).copy()
X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape

"""Now, we consider different models and create a list of dictionaries for GridSearchCV."""

# Define models and hyperparameters to search over
models = [
    {
        'name': 'Logistic Regression CV',
        'model': LogisticRegressionCV(),
        'params': {
            'model__penalty': ['l1', 'l2'],
            'model__solver': ['newton-cg', 'newton-cholesky', 'sag']
        }
    },
    {
        'name': 'KNN',
        'model': KNeighborsClassifier(),
        'params': {
            'model__n_neighbors': [3, 5, 7, 9],
            'model__weights': ['uniform', 'distance'],
            'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']
        }
    },
    {
        'name': 'SVM',
        'model': SVC(),
        'params': {
            'model__C': [0.1, 1, 10],
            'model__kernel': ['linear', 'rbf', 'poly']
        }
    },
    {
        'name': 'GaussianNB',
        'model': GaussianNB(),
        'params': {
             'model__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]
             }
    },
    {
        'name': 'SGD',
        'model': SGDClassifier(),
        'params': {
             'model__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],
             'model__penalty': ['l2', 'l1', 'elasticnet'],
             'model__alpha': [0.0001, 0.001, 0.01, 0.1],
             'model__max_iter': [1000, 2000, 5000],
              }
    },
    {
        'name': 'Decision Tree',
        'model': DecisionTreeClassifier(),
        'params': {
             'model__max_depth': [3, 5, 7],
             'model__min_samples_split': [2, 5, 10],
             'model__min_samples_leaf': [1, 2, 4],
              }
    },
    {
        'name': 'Random Forest',
        'model': RandomForestClassifier(),
        'params': {
             'model__n_estimators': [100, 200],
             'model__max_depth': [10, 20, 30],
             'model__min_samples_split': [2, 5, 10],
             'model__min_samples_leaf': [1, 2, 4]
              }
    }
]

"""Now we'll apply all the models and use different metrics for evaluation:"""

scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']

model_results = {}
for sc in scoring_metrics:
    model_results[sc] = {}
    print(f'Metrics: {sc}')
    for i, model in enumerate(models):
        start_time = time.time()
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('model', model['model'])
        ])
        param_grid = model['params']
        grid = GridSearchCV(pipeline, param_grid, cv=5, scoring=sc, refit=True)
        grid.fit(X_train, Y_train)
        end_time = time.time()

        # Calculate time taken for grid search
        elapsed_time = end_time - start_time

        # Store results for this model in dictionary
        model_result = {}
        model_result['name'] = model['name']
        model_result['best_params'] = grid.best_params_
        model_result['score'] = grid.best_score_
        model_result['time_taken'] = elapsed_time

        model_results[sc][i] = model_result

        # Print progress update
        progress_percent = ((i+1)/len(models)) * 100
        print("Completed {} out of {} models ({:.2f}% done)".format(i+1, len(models), progress_percent))

model_results['f1']

"""Let's plot some bar diagrams to visualize performance of the models."""

import matplotlib.pyplot as plt

# Get names of models
model_names = [model_results['accuracy'][i]['name'] for i in range(len(model_results['accuracy']))]

# Get scores for each model
accuracy_scores = [model_results['accuracy'][i]['score'] for i in range(len(model_results['accuracy']))]
precision_scores = [model_results['precision'][i]['score'] for i in range(len(model_results['precision']))]
recall_scores = [model_results['recall'][i]['score'] for i in range(len(model_results['recall']))]
f1_scores = [model_results['f1'][i]['score'] for i in range(len(model_results['recall']))]

# Set up plot
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_title('Model Performance')
ax.set_xlabel('Model')
ax.set_ylabel('Score')
ax.set_ylim([0.6,1])

# Plot scores
ax.bar(model_names, accuracy_scores, label='Accuracy', alpha=0.5)
ax.bar(model_names, precision_scores, label='Precision', alpha=0.5)
ax.bar(model_names, recall_scores, label='Recall', alpha=0.5)
ax.bar(model_names, f1_scores, label='F1-score', alpha=0.5)

# Add legend and show plot
ax.legend()
plt.show()

"""Let's extract our results from the best models for each metric:"""

for metric in scoring_metrics:
    best_model = max(range(len(model_results[metric])), key=lambda x: model_results[metric][x]['score'])
    print(f"Best {metric} model: {model_results[metric][best_model]['name']}")
    print(f"Score: {model_results[metric][best_model]['score']}")
    print(f"Parameters: {model_results[metric][best_model]['best_params']}")
    print()

"""Finally, we'll create a file with the target value for each model and we can submit it as a result of our prediction."""

X_train = train_df.drop(["Survived", "PassengerId"], axis=1)
Y_train = train_df["Survived"]

model_1 = RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200)
model_1.fit(X_train, Y_train)
Y_pred = model_1.predict(X_test)

submission = pd.DataFrame({
        "PassengerId": test_df["PassengerId"],
        "Survived": Y_pred
    })
submission.to_csv('RFC_1.csv', index=False)

model_2 = SVC(C=0.1, kernel='poly')
model_2.fit(X_train, Y_train)
Y_pred = model_2.predict(X_test)

submission = pd.DataFrame({
        "PassengerId": test_df["PassengerId"],
        "Survived": Y_pred
    })
submission.to_csv('SVM.csv', index=False)

model_3 = SGDClassifier(alpha=0.1, loss='perceptron', max_iter=2000, penalty='l1')
model_3.fit(X_train, Y_train)
Y_pred = model_3.predict(X_test)

submission = pd.DataFrame({
        "PassengerId": test_df["PassengerId"],
        "Survived": Y_pred
    })
submission.to_csv('SGD.csv', index=False)

model_4 = RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100)
model_4.fit(X_train, Y_train)
Y_pred = model_4.predict(X_test)

submission = pd.DataFrame({
        "PassengerId": test_df["PassengerId"],
        "Survived": Y_pred
    })
submission.to_csv('RFC_2.csv', index=False)

"""###Links
Kaggle competition - https://www.kaggle.com/competitions/titanic
"""